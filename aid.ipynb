{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Data Preparation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'src\\rawDataset.csv')\n",
    "\n",
    "df.drop(columns=['RowNumber','Surname','CustomerId', 'Complain'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 30, 40, 50, 60, 100]  \n",
    "labels = ['<30', '30-40', '40-50', '50-60', '>60']\n",
    "\n",
    "df['Age'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codification\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first', dtype=int)\n",
    "\n",
    "catcols = ['Gender','Geography', 'Card Type', 'Age']\n",
    "encData = encoder.fit_transform(df[catcols])\n",
    "encDF = pd.DataFrame(encData, columns=encoder.get_feature_names_out(catcols))\n",
    "df = pd.concat([df.drop(columns= catcols),encDF],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df[['Balance', 'EstimatedSalary']] = scaler.fit_transform(df[['Balance', 'EstimatedSalary']])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wrapped method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Forward Selection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Exited'])\n",
    "y = df['Exited']\n",
    "\n",
    "selected_features = []\n",
    "feature_names = list(X.columns)\n",
    "scores_list = []\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "accuracy_threshold = 0.01\n",
    "max_no_improvement_iterations = 5\n",
    "no_improvement_count = 0\n",
    "best_score = -1\n",
    "\n",
    "while len(selected_features) < 13:\n",
    "    best_score = -1\n",
    "    best_feature = None\n",
    "\n",
    "    for feature_idx in range(X.shape[1]):\n",
    "        if feature_idx in selected_features:\n",
    "            continue\n",
    "\n",
    "        candidate_features = selected_features + [feature_idx]\n",
    "        candidate_feature_names = [feature_names[i] for i in candidate_features]\n",
    "\n",
    "        # cross-validation\n",
    "        scores = cross_val_score(model, X[candidate_feature_names], y, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        mean_score = np.mean(scores)\n",
    "\n",
    "        # best-performing feature\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_feature = feature_idx\n",
    "\n",
    "    if best_feature is not None:\n",
    "        selected_features.append(best_feature)\n",
    "        scores_list.append(best_score)\n",
    "\n",
    "        print(f\"Selected Feature {len(selected_features)}: {feature_names[best_feature]}, Mean Accuracy: {best_score:.4f}\")\n",
    "\n",
    "        if abs(best_score - np.mean(cross_val_score(model, X[[feature_names[i] for i in selected_features]], y, cv=5))) < accuracy_threshold:\n",
    "            no_improvement_count += 1\n",
    "        else:\n",
    "            no_improvement_count = 0\n",
    "        \n",
    "        # Stop if there's no improvement for a predefined number of iterations\n",
    "        if no_improvement_count >= max_no_improvement_iterations:\n",
    "            print(\"Stopping early due to lack of significant improvement.\")\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table = go.Figure(data=[go.Table(\n",
    "    header=dict(values=[\"<b>Selection Order</b>\", \"<b>Feature Name</b>\"],\n",
    "                fill_color='lightgrey',\n",
    "                align='center'),\n",
    "    cells=dict(values=[list(range(1, len(selected_features) + 1)),\n",
    "                       [feature_names[i] for i in selected_features]],\n",
    "               fill_color='white',\n",
    "               align='center')\n",
    ")])\n",
    "\n",
    "table.update_layout(title=\"Feature Selection Order\")\n",
    "table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Backward Elimination*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = list(range(X.shape[1]))\n",
    "min_features_to_retain = 5\n",
    "\n",
    "removed_features = []\n",
    "accuracy_scores = []\n",
    "\n",
    "while len(all_features) > min_features_to_retain:\n",
    "    worst_score = 1.0  \n",
    "    worst_feature = None\n",
    "\n",
    "    for feature_idx in all_features:\n",
    "\n",
    "        candidate_features = [f for f in all_features if f != feature_idx]\n",
    "        candidate_feature_names = [feature_names[i] for i in candidate_features]\n",
    "\n",
    "        # cross-validation\n",
    "        scores = cross_val_score(model, X[candidate_feature_names], y, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        mean_score = np.mean(scores)\n",
    "\n",
    "        # worst-performing feature\n",
    "        if mean_score < worst_score:\n",
    "            worst_score = mean_score\n",
    "            worst_feature = feature_idx\n",
    "\n",
    "    if worst_feature is not None:\n",
    "        all_features.remove(worst_feature)\n",
    "        removed_features.append(feature_names[worst_feature])\n",
    "        accuracy_scores.append(worst_score)\n",
    "        print(f\"Removed Feature : {feature_names[worst_feature]}, Mean Accuracy: {worst_score:.4f}\")\n",
    "\n",
    "print(\"Remaining feature indices:\", {feature_names[i] for i in all_features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(1, len(removed_features) + 1)),\n",
    "    y=accuracy_scores,\n",
    "    mode='lines+markers',\n",
    "    text=removed_features,\n",
    "    hovertemplate='<b>Step %{x}</b><br>Removed Feature: %{text}<br>Mean Accuracy: %{y:.4f}<extra></extra>',\n",
    "    name='Backward Elimination'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Backward Elimination Process\",\n",
    "    xaxis_title=\"Number of Features Removed\",\n",
    "    yaxis_title=\"Mean Accuracy\",\n",
    "    hovermode=\"closest\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Selection Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sfm_selector = SelectFromModel(estimator=model)\n",
    "sfm_selector.fit(X, y)\n",
    "features = X.columns[sfm_selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = go.Figure(data=[go.Table(\n",
    "    header=dict(values=[\"<b>Feature Name</b>\"],\n",
    "                fill_color='lightgrey',\n",
    "                align='center'),\n",
    "    cells=dict(values=[features],\n",
    "               fill_color='white',\n",
    "               align='center')\n",
    ")])\n",
    "\n",
    "\n",
    "table.update_layout(title=\"Feature Selection Order\")\n",
    "table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Feature Selection Sequential Feature Selection (SFS)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.01\n",
    "vt = VarianceThreshold(threshold=threshold)\n",
    "X_reduced = vt.fit_transform(X)\n",
    "\n",
    "sfs_selector = SequentialFeatureSelector(estimator=model, n_features_to_select = 3, cv =5, direction ='backward', n_jobs=-1)\n",
    "sfs_selector.fit(X_reduced, y)\n",
    "features = X.columns[sfs_selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = go.Figure(data=[go.Table(\n",
    "    header=dict(values=[\"<b>Feature Name</b>\"],\n",
    "                fill_color='lightgrey',\n",
    "                align='center'),\n",
    "    cells=dict(values=[features],\n",
    "               fill_color='white',\n",
    "               align='center')\n",
    ")])\n",
    "\n",
    "\n",
    "table.update_layout(title=\"Feature Selection Order\")\n",
    "table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Recursive Feature Elimination (RFE)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "num_features_to_retain = 5\n",
    "rfe = RFE(estimator=model, n_features_to_select=num_features_to_retain)\n",
    "\n",
    "# Fit the RFE\n",
    "rfe.fit(X, y)\n",
    "\n",
    "\n",
    "selected_features = np.where(rfe.support_)[0]\n",
    "\n",
    "print(\"Selected feature indices:\", [feature_names[i] for i in selected_features])\n",
    "\n",
    "# cross-validation\n",
    "scores = cross_val_score(model, X[[feature_names[i] for i in selected_features]], y, cv=5, scoring='accuracy')\n",
    "mean_accuracy = np.mean(scores)\n",
    "print(f\"Mean Accuracy with Selected Features: {mean_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(\n",
    "        values=[\"<b>Selected Features</b>\", \"<b>Mean Accuracy</b>\"],\n",
    "        fill_color=\"lightblue\",\n",
    "        align=\"center\",\n",
    "        font=dict(size=14, color=\"black\")\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=[[feature_names[i] for i in selected_features], [f\"{mean_accuracy:.4f}\"]],\n",
    "        fill_color=\"white\",\n",
    "        align=\"center\",\n",
    "        font=dict(size=12)\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Selected Features and Model Accuracy\",\n",
    "    title_x=0.5,\n",
    "    template=\"plotly_white\",\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Exhaustive Search*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(tree_method='gpu_hist', gpu_id=0)\n",
    "\n",
    "max_features = 5\n",
    "\n",
    "# Initialize variables to keep track of the best feature subset and its accuracy\n",
    "best_subset = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Generate all possible combinations of feature indices\n",
    "all_feature_combinations = list(combinations(range(X.shape[1]), max_features))\n",
    "\n",
    "for feature_subset in all_feature_combinations:\n",
    "    feature_subset = list(feature_subset)\n",
    "    \n",
    "    # Evaluate the model's performance using cross-validation\n",
    "    X_subset = X.iloc[:, feature_subset]\n",
    "    scores = cross_val_score(model, X_subset, y, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    mean_accuracy = np.mean(scores)\n",
    "\n",
    "    # Check if this feature subset is better than the best one found so far\n",
    "    if mean_accuracy > best_accuracy:\n",
    "        best_accuracy = mean_accuracy\n",
    "        best_subset = feature_subset\n",
    "\n",
    "print(\"Best Feature Subset:\", best_subset)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(\n",
    "        values=[\"<b>Selected Features</b>\", \"<b>Mean Accuracy</b>\"],\n",
    "        fill_color=\"lightblue\",\n",
    "        align=\"center\",\n",
    "        font=dict(size=14, color=\"black\")\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=[[feature_names[i] for i in best_subset], [f\"{best_accuracy:.4f}\"]],\n",
    "        fill_color=\"white\",\n",
    "        align=\"center\",\n",
    "        font=dict(size=12)\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Estilizar y mostrar la tabla\n",
    "fig.update_layout(\n",
    "    title=\"Selected Features and Model Accuracy\",\n",
    "    title_x=0.5,\n",
    "    template=\"plotly_white\",\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
